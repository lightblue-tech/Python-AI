{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSmK92T5m8fS"
   },
   "outputs": [],
   "source": [
    "# @title ライブラリのインポート\n",
    "\n",
    "import colorsys\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utU9k4FAzaY9"
   },
   "source": [
    "\n",
    "\n",
    "ライブラリのバージョンの確認方法\n",
    "```\n",
    "# OpenCVのバージョン\n",
    "import cv2\n",
    "print(f\"OpenCV (cv2) バージョン: {cv2.__version__}\")\n",
    "\n",
    "# NumPyのバージョン\n",
    "import numpy as np\n",
    "print(f\"NumPy バージョン: {np.__version__}\")\n",
    "\n",
    "# Matplotlibのバージョン\n",
    "import matplotlib\n",
    "print(f\"Matplotlib バージョン: {matplotlib.__version__}\")\n",
    "\n",
    "# pydanticのバージョン\n",
    "import pydantic\n",
    "print(f\"pydantic バージョン: {pydantic.__version__}\")\n",
    "\n",
    "# tqdmのバージョン\n",
    "import tqdm\n",
    "print(f\"tqdm バージョン: {tqdm.__version__}\")\n",
    "```\n",
    "\n",
    "```\n",
    "OpenCV (cv2) バージョン: 4.10.0\n",
    "NumPy バージョン: 1.26.4\n",
    "Matplotlib バージョン: 3.10.0\n",
    "pydantic バージョン: 2.10.4\n",
    "tqdm バージョン: 4.67.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-IOacUV5W1V"
   },
   "source": [
    "# パイプラインの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8h_j-TGvoCl2"
   },
   "outputs": [],
   "source": [
    "# @title Configオブジェクト（設定値を格納するオブジェクト）\n",
    "\n",
    "\n",
    "class Config(BaseModel):\n",
    "    \"\"\"\n",
    "    動画処理に関する設定パラメータを管理するクラス\n",
    "    \"\"\"\n",
    "\n",
    "    # 入力動画に関する設定\n",
    "    video_dir: str\n",
    "    \"\"\"動画ファイルが保存されているディレクトリのパス\n",
    "    例: '/content/videos/' や 'C:/Users/username/videos/'\n",
    "    \"\"\"\n",
    "\n",
    "    video_filename: str\n",
    "    \"\"\"処理対象の動画ファイル名\n",
    "    例: 'input.mp4' や 'sample_video.avi'\n",
    "    \"\"\"\n",
    "\n",
    "    motion_detector_th_size: float\n",
    "    \"\"\"動き検出の閾値サイズ\n",
    "    小さすぎると細かなノイズも検出し、大きすぎると重要な動きを見逃す可能性がある\n",
    "    \"\"\"\n",
    "\n",
    "    output_video_fps: float\n",
    "    \"\"\"出力動画のフレームレート（1秒あたりのフレーム数）\n",
    "    \"\"\"\n",
    "\n",
    "    output_video_size: tuple[int, int]\n",
    "    \"\"\"出力動画の解像度を(幅, 高さ)のタプルで指定\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def video_src_path(self) -> str:\n",
    "        \"\"\"\n",
    "        入力動画ファイルの完全パスを取得するプロパティ\n",
    "\n",
    "        Returns:\n",
    "            str: 動画ファイルの完全パス\n",
    "                 例: '/content/videos/input.mp4'\n",
    "        \"\"\"\n",
    "        return os.path.join(self.video_dir, self.video_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_q4NPsYkHN0"
   },
   "outputs": [],
   "source": [
    "# @title BBoxオブジェクト（画像上の矩形領域（バウンディングボックス）を表現する）\n",
    "\n",
    "\n",
    "class BBox(BaseModel):\n",
    "    \"\"\"\n",
    "    画像上の矩形領域（バウンディングボックス）を表現するクラス\n",
    "    BaseModelを継承して、座標値のバリデーションを行う\n",
    "\n",
    "    座標系:\n",
    "    - 原点(0,0)は画像の左上\n",
    "    - x軸は右方向が正\n",
    "    - y軸は下方向が正\n",
    "    \"\"\"\n",
    "\n",
    "    left: float\n",
    "    \"\"\"矩形の左端のx座標（ピクセル単位）\n",
    "    例: left=100.0 は画像の左端から100ピクセルの位置\n",
    "    \"\"\"\n",
    "\n",
    "    top: float\n",
    "    \"\"\"矩形の上端のy座標（ピクセル単位）\n",
    "    例: top=50.0 は画像の上端から50ピクセルの位置\n",
    "    \"\"\"\n",
    "\n",
    "    right: float\n",
    "    \"\"\"矩形の右端のx座標（ピクセル単位）\n",
    "    必ず left < right となるべき\n",
    "    \"\"\"\n",
    "\n",
    "    bottom: float\n",
    "    \"\"\"矩形の下端のy座標（ピクセル単位）\n",
    "    必ず top < bottom となるべき\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def ltrb(self) -> tuple[float, float, float, float]:\n",
    "        \"\"\"\n",
    "        バウンディングボックスの4つの座標値をタプルで取得するプロパティ\n",
    "\n",
    "        Returns:\n",
    "            tuple[float, float, float, float]:\n",
    "                (left, top, right, bottom)の順での座標値のタプル\n",
    "        \"\"\"\n",
    "        return self.left, self.top, self.right, self.bottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEBGGV1tp5p5"
   },
   "outputs": [],
   "source": [
    "# @title Detectionオブジェクト（結果を格納するオブジェクト）\n",
    "\n",
    "\n",
    "class Detection:\n",
    "    \"\"\"\n",
    "    検出結果を扱うクラス\n",
    "    バウンディングボックスの情報を保持し、画像上に描画する機能を提供\n",
    "    \"\"\"\n",
    "\n",
    "    bbox: BBox | None\n",
    "    \"\"\"検出された物体の境界ボックス\n",
    "    検出結果が存在しない場合はNone\n",
    "    \"\"\"\n",
    "\n",
    "    def draw(self, img: np.ndarray):\n",
    "        \"\"\"\n",
    "        検出結果を画像上に描画するメソッド\n",
    "\n",
    "        Args:\n",
    "            img: 描画対象の画像（OpenCV形式、BGR）\n",
    "\n",
    "        Note:\n",
    "            内部で_draw_bboxを呼び出してバウンディングボックスを描画\n",
    "        \"\"\"\n",
    "        self._draw_bbox(img)\n",
    "\n",
    "    def _draw_bbox(self, img: np.ndarray):\n",
    "        \"\"\"\n",
    "        バウンディングボックスを画像上に描画する内部メソッド\n",
    "\n",
    "        Args:\n",
    "            img: 描画対象の画像（OpenCV形式、BGR）\n",
    "\n",
    "        Note:\n",
    "            - 緑色(BGR=(0,255,0))の矩形を描画\n",
    "            - 線の太さは2ピクセル\n",
    "            - cv2.rectangleを使用して描画\n",
    "        \"\"\"\n",
    "        cv2.rectangle(\n",
    "            img,  # 描画対象の画像\n",
    "            pt1=(self.bbox.left, self.bbox.top),  # 矩形の左上頂点\n",
    "            pt2=(self.bbox.right, self.bbox.bottom),  # 矩形の右下頂点\n",
    "            color=(0, 255, 0),  # 緑色（BGR形式）\n",
    "            thickness=2,  # 線の太さ（ピクセル）\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCTavgubqqJz"
   },
   "outputs": [],
   "source": [
    "# @title Driftingオブジェクト（フレームごとの結果を保存するオブジェクト）\n",
    "\n",
    "\n",
    "class Drifting:\n",
    "    img: np.ndarray  # 動画のフレーム\n",
    "    count: int  # 現在のフレームのインデックス番号\n",
    "    detections: list[Detection]  # 検出結果\n",
    "    result_img: np.ndarray  # 検出結果を描画したフレーム\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS_BcvZmnsTm"
   },
   "outputs": [],
   "source": [
    "# @title 動画読み込みエレメント\n",
    "\n",
    "\n",
    "class VideoFileSrc:\n",
    "    \"\"\"\n",
    "    動画ファイルからフレームを読み込むためのクラス\n",
    "    OpenCVのVideoCapture機能を使用して動画ファイルを扱う\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        初期化メソッド\n",
    "\n",
    "        Args:\n",
    "            config: 動画処理の設定情報を含むConfigオブジェクト\n",
    "        \"\"\"\n",
    "        # フレーム管理用の変数を初期化\n",
    "        self.frame_num = 0  # 現在のフレーム番号（0からスタート）\n",
    "\n",
    "        # 動画ファイルのパスを設定\n",
    "        self.video_src_path = config.video_src_path\n",
    "\n",
    "        # VideoCaptureオブジェクトを生成して動画ファイルを開く\n",
    "        self.cap = cv2.VideoCapture(self.video_src_path)\n",
    "\n",
    "        # 動画の基本情報を取得\n",
    "        # CAP_PROPプロパティを使用して動画の属性を読み取る\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 総フレーム数\n",
    "        self.fps = round(self.cap.get(cv2.CAP_PROP_FPS))  # フレームレート\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 高さ（ピクセル）\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 幅（ピクセル）\n",
    "\n",
    "    def read(self) -> Drifting:\n",
    "        \"\"\"\n",
    "        動画から1フレームを読み込むメソッド\n",
    "\n",
    "        Returns:\n",
    "            Drifting: 読み込んだフレーム情報を含むDriftingオブジェクト\n",
    "\n",
    "        Note:\n",
    "            - フレームごとに進捗状況をコンソールに表示\n",
    "            - フレーム番号は自動的にインクリメント\n",
    "        \"\"\"\n",
    "        # 新しいDriftingオブジェクトを生成\n",
    "        drifting = Drifting()\n",
    "\n",
    "        # フレームを読み込む\n",
    "        _, drifting.img = self.cap.read()\n",
    "\n",
    "        # 現在のフレーム番号を設定\n",
    "        drifting.count = self.frame_num\n",
    "\n",
    "        # 次のフレーム用にカウンタをインクリメント\n",
    "        self.frame_num += 1\n",
    "\n",
    "        return drifting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WStxyJjJ1tzv"
   },
   "outputs": [],
   "source": [
    "# @title 動画書き出しエレメント\n",
    "\n",
    "\n",
    "class VideoSink:\n",
    "    \"\"\"\n",
    "    処理済みフレームを動画ファイルとして保存するクラス\n",
    "    OpenCVのVideoWriterを使用して動画ファイルを生成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        初期化メソッド\n",
    "\n",
    "        Args:\n",
    "            config: 動画処理の設定情報を含むConfigオブジェクト\n",
    "\n",
    "        Note:\n",
    "            MP4形式で出力するようにコーデックを設定\n",
    "        \"\"\"\n",
    "        # 出力ファイルのパスを生成（元のファイル名 + \"_out.mp4\"）\n",
    "        self.output_path = self.generate_output_path(config.video_src_path)\n",
    "\n",
    "        # VideoWriterオブジェクトを初期化\n",
    "        self.writer = cv2.VideoWriter(\n",
    "            self.output_path,  # 出力先のファイルパス\n",
    "            cv2.VideoWriter_fourcc(\"m\", \"p\", \"4\", \"v\"),  # MP4フォーマット用のコーデック\n",
    "            config.output_video_fps,  # 出力フレームレート（FPS）\n",
    "            config.output_video_size,  # 出力解像度（幅, 高さ）\n",
    "        )\n",
    "\n",
    "    def write(self, drifting: Drifting) -> Drifting:\n",
    "        \"\"\"\n",
    "        1フレームを動画ファイルに書き出すメソッド\n",
    "\n",
    "        Args:\n",
    "            drifting: 処理済みフレーム情報を含むDriftingオブジェクト\n",
    "\n",
    "        Returns:\n",
    "            Drifting: 入力されたDriftingオブジェクトをそのまま返す\n",
    "\n",
    "        Note:\n",
    "            result_imgプロパティに格納された処理済み画像を書き出し\n",
    "        \"\"\"\n",
    "        # 処理済み画像を動画ファイルに書き出し\n",
    "        self.writer.write(drifting.result_img)\n",
    "        return drifting\n",
    "\n",
    "    def release(self):\n",
    "        \"\"\"\n",
    "        VideoWriterのリソースを解放するメソッド\n",
    "\n",
    "        Note:\n",
    "            - 動画ファイルの書き出しが完了したら必ず呼び出す\n",
    "            - リソースの解放を忘れると、ファイルが正しく保存されない可能性がある\n",
    "        \"\"\"\n",
    "        self.writer.release()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_output_path(file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        入力ファイルパスから出力ファイルパスを生成する静的メソッド\n",
    "\n",
    "        Args:\n",
    "            file_path: 入力動画ファイルのパス\n",
    "\n",
    "        Returns:\n",
    "            str: 出力動画ファイルのパス\n",
    "\n",
    "        Example:\n",
    "            入力: \"/path/to/video.avi\"\n",
    "            出力: \"/path/to/video_out.mp4\"\n",
    "        \"\"\"\n",
    "        # 入力ファイルのパスから拡張子を除いた部分を取得\n",
    "        file_name_without_ext, _ = os.path.splitext(file_path)\n",
    "\n",
    "        # 新しいファイル名を生成（元のファイル名 + \"_out.mp4\"）\n",
    "        new_file_path = f\"{file_name_without_ext}_out.mp4\"\n",
    "\n",
    "        return new_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcJn9VjJnfGa"
   },
   "outputs": [],
   "source": [
    "# @title 動き検知エレメント\n",
    "\n",
    "\n",
    "class MotionDetector:\n",
    "    \"\"\"\n",
    "    動画内の動きを検出するクラス\n",
    "    背景差分法とMOG（Mixture of Gaussian）アルゴリズムを使用して\n",
    "    動いているオブジェクトを検出する\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        初期化メソッド\n",
    "\n",
    "        Args:\n",
    "            config: 動画処理の設定情報を含むConfigオブジェクト\n",
    "\n",
    "        Note:\n",
    "            MOGアルゴリズムは、各ピクセルの背景をガウス分布の混合でモデル化し、\n",
    "            動的な背景に対しても効果的に動体検出を行える\n",
    "        \"\"\"\n",
    "        # MOGアルゴリズムによる背景分離器を生成\n",
    "        self.model = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "        # 動き検出の閾値サイズを設定（小さすぎるノイズを除去するため）\n",
    "        self.th_size = config.motion_detector_th_size\n",
    "\n",
    "    def detect(self, drifting: Drifting) -> Drifting:\n",
    "        \"\"\"\n",
    "        フレーム内の動きを検出するメソッド\n",
    "\n",
    "        Args:\n",
    "            drifting: 処理対象フレームを含むDriftingオブジェクト\n",
    "\n",
    "        Returns:\n",
    "            Drifting: 動き検出結果を追加したDriftingオブジェクト\n",
    "\n",
    "        処理の流れ:\n",
    "            1. 背景差分による動き検出\n",
    "            2. 輪郭検出\n",
    "            3. サイズによるフィルタリング\n",
    "            4. バウンディングボックスの生成\n",
    "        \"\"\"\n",
    "        # 背景差分法で動きのあるピクセルをマスクとして抽出\n",
    "        mask = self.model.apply(drifting.img)\n",
    "\n",
    "        # マスクから輪郭を検出\n",
    "        # RETR_EXTERNAL: 最も外側の輪郭のみを検出\n",
    "        # CHAIN_APPROX_SIMPLE: 輪郭を直線で近似して記憶効率を向上\n",
    "        contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        # 閾値サイズより大きい輪郭のみをフィルタリング\n",
    "        contours = list(filter(lambda x: cv2.contourArea(x) > self.th_size, contours))\n",
    "\n",
    "        # 各輪郭を囲む最小の矩形を計算\n",
    "        bboxes = list(map(lambda x: cv2.boundingRect(x), contours))\n",
    "\n",
    "        # 各バウンディングボックスをDetectionオブジェクトに変換\n",
    "        drifting.detections = [self.postprocess(bbox) for bbox in bboxes]\n",
    "\n",
    "        return drifting\n",
    "\n",
    "    @staticmethod\n",
    "    def postprocess(bbox: tuple[int, int, int, int]) -> Detection:\n",
    "        \"\"\"\n",
    "        OpenCVの矩形形式(x, y, w, h)をDetectionオブジェクトに変換\n",
    "\n",
    "        Args:\n",
    "            bbox: OpenCV形式のバウンディングボックス\n",
    "                 (左上x座標, 左上y座標, 幅, 高さ)\n",
    "\n",
    "        Returns:\n",
    "            Detection: 変換後のDetectionオブジェクト\n",
    "        \"\"\"\n",
    "        detection = Detection()\n",
    "        detection.bbox = BBox(\n",
    "            left=bbox[0],  # 左端のx座標\n",
    "            top=bbox[1],  # 上端のy座標\n",
    "            right=bbox[0] + bbox[2],  # 左端 + 幅 = 右端\n",
    "            bottom=bbox[1] + bbox[3],  # 上端 + 高さ = 下端\n",
    "        )\n",
    "        return detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2gCtXuYoV_E"
   },
   "outputs": [],
   "source": [
    "# @title 結果描画エレメント\n",
    "\n",
    "GOLDEN_RATIO = 0.618033988749895  # 黄金比（描画色の選択に使用）\n",
    "\n",
    "\n",
    "class DetectionRenderer:\n",
    "    \"\"\"\n",
    "    検出結果を視覚化するクラス\n",
    "    黄金比を利用して異なる物体に異なる色を割り当て、バウンディングボックスを描画する\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"初期化メソッド\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_color(\n",
    "        self, idx: int, s: float = 0.8, vmin: float = 0.7\n",
    "    ) -> tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        検出物体ごとに異なる色を生成するメソッド\n",
    "        黄金比を使用して、見分けやすい色の組み合わせを生成\n",
    "\n",
    "        Args:\n",
    "            idx: 物体のインデックス\n",
    "            s: 彩度（0.0-1.0）\n",
    "            vmin: 最小明度（0.0-1.0）\n",
    "\n",
    "        Returns:\n",
    "            tuple[int, int, int]: BGR形式の色情報（各要素は0-255）\n",
    "\n",
    "        Note:\n",
    "            黄金比を使用することで、連続する数値でも視覚的に異なる色を生成できる\n",
    "        \"\"\"\n",
    "        # 黄金比を使って色相を計算（0.0-1.0の範囲）\n",
    "        h = np.fmod(idx * GOLDEN_RATIO, 1.0)\n",
    "\n",
    "        # 明度を計算（vmin-1.0の範囲）\n",
    "        v = 1.0 - np.fmod(idx * GOLDEN_RATIO, 1.0 - vmin)\n",
    "\n",
    "        # HSV色空間からRGB色空間に変換\n",
    "        r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "\n",
    "        # RGB値を0-255の整数値に変換してBGR形式で返す\n",
    "        return int(255 * b), int(255 * g), int(255 * r)\n",
    "\n",
    "    def add_bbox(\n",
    "        self,\n",
    "        result_img: np.ndarray,\n",
    "        bbox: BBox,\n",
    "        color: tuple[int] = (255, 0, 0),  # デフォルトは青色\n",
    "    ):\n",
    "        \"\"\"\n",
    "        バウンディングボックスを画像に描画するメソッド\n",
    "\n",
    "        Args:\n",
    "            result_img: 描画対象の画像\n",
    "            bbox: 描画するバウンディングボックス\n",
    "            color: 描画色（BGR形式、デフォルトは青）\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: バウンディングボックスが描画された画像\n",
    "        \"\"\"\n",
    "        # バウンディングボックスの座標を整数に変換\n",
    "        bbox_ = [int(p) for p in bbox.ltrb]\n",
    "\n",
    "        # OpenCVで矩形を描画\n",
    "        result_img = cv2.rectangle(\n",
    "            result_img,\n",
    "            pt1=(bbox_[2], bbox_[3]),  # 右下点\n",
    "            pt2=(bbox_[0], bbox_[1]),  # 左上点\n",
    "            color=color,  # 描画色\n",
    "            thickness=2,  # 線の太さ\n",
    "        )\n",
    "        return result_img\n",
    "\n",
    "    def draw_result(self, drifting: Drifting):\n",
    "        \"\"\"\n",
    "        検出結果全体を画像に描画するメソッド\n",
    "\n",
    "        Args:\n",
    "            drifting: 検出結果と画像を含むDriftingオブジェクト\n",
    "\n",
    "        Returns:\n",
    "            Drifting: 描画結果を追加したDriftingオブジェクト\n",
    "\n",
    "        Note:\n",
    "            各検出物体に異なる色を割り当てて描画\n",
    "        \"\"\"\n",
    "        # 入力画像が存在する場合のみ処理\n",
    "        if drifting.img is not None:\n",
    "            # 入力画像をコピーして描画用の画像を作成\n",
    "            result_img: np.ndarray = drifting.img.copy()\n",
    "\n",
    "            # 各検出結果に対して処理\n",
    "            for id, detection in enumerate(drifting.detections):\n",
    "                # 型チェック: 正しいクラスのインスタンスか確認\n",
    "                assert isinstance(detection, Detection)\n",
    "\n",
    "                # 物体ごとに異なる色を生成\n",
    "                color = self.get_color(id)\n",
    "\n",
    "                # バウンディングボックスが存在する場合は描画\n",
    "                if detection.bbox is not None:\n",
    "                    result_img = self.add_bbox(result_img, detection.bbox, color)\n",
    "\n",
    "            # 描画結果をdriftingオブジェクトに保存\n",
    "            drifting.result_img = result_img\n",
    "\n",
    "        return drifting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyM2LuEH5KT7"
   },
   "source": [
    "# メイン処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX4n4rWP4mnn"
   },
   "source": [
    "下記のURLから動画ファイルをダウンロードしてください。サイズは1920×1080にしてください。ダウンロード後、Google Colabにアップロードしてください。\n",
    "\n",
    "\n",
    "\n",
    "**[動画のURL](https://pixabay.com/ja/videos/%E8%B5%B0%E3%82%8B-%E3%83%95%E3%82%A3%E3%83%BC%E3%83%AB%E3%83%89-%E7%94%B7-%E4%BA%BA-45711/)**\n",
    "\n",
    "\n",
    "\n",
    "> <a href=\"https://pixabay.com/ja//?utm_source=link-attribution&utm_medium=referral&utm_campaign=video&utm_content=45711\">Pixabay</a>が提供する<a href=\"https://pixabay.com/ja/users/sergo75-75-14395311/?utm_source=link-attribution&utm_medium=referral&utm_campaign=video&utm_content=45711\">Sergey Semenov</a>の動画\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSLgqdRe5nKk"
   },
   "outputs": [],
   "source": [
    "# @title 動画ファイルのパスの指定\n",
    "\n",
    "video_dir = \"/content\"  # @param {type:\"string\"}\n",
    "video_filename = \"45711-446485467_small.mp4\"  # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn_Hk7Ze58Uc"
   },
   "outputs": [],
   "source": [
    "# @title 動き検出器のパラメータ設定\n",
    "\n",
    "motion_detector_th_size = 100.0  # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvWHpd6p6L2R"
   },
   "outputs": [],
   "source": [
    "# @title 出力動画の設定\n",
    "\n",
    "output_video_fps = 30.0  # @param\n",
    "output_video_size = (1920, 1080)  # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VicA5zK6SnQ"
   },
   "outputs": [],
   "source": [
    "# @title 設定値の統合\n",
    "\n",
    "config = Config(\n",
    "    video_dir=video_dir,  # 動画ファイルのディレクトリ\n",
    "    video_filename=video_filename,  # 動画ファイル名\n",
    "    motion_detector_th_size=motion_detector_th_size,  # 動き検出の閾値\n",
    "    output_video_fps=output_video_fps,  # 出力フレームレート\n",
    "    output_video_size=output_video_size,  # 出力解像度\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlp87aUs6y-1"
   },
   "outputs": [],
   "source": [
    "# @title 処理エレメントの初期化\n",
    "\n",
    "video_src = VideoFileSrc(config)  # 動画入力\n",
    "video_sink = VideoSink(config)  # 動画出力\n",
    "motion_detector = MotionDetector(config)  # 動き検出\n",
    "detection_renderer = DetectionRenderer()  # 結果描画\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "26299cf17869440981a8998dc7ac9216",
      "4b6e28f789ca4604b29ce5f714cd891c",
      "988f04379ee343c7a6b61af47bf82a90",
      "3c33dadfbf73401e8035a2781a8b6c76",
      "4dea107052924011a62a21a322c7a09d",
      "9f77c6deb0204302b03b501c08802685",
      "8ade06b9d59b4fb3a6756ee782304186",
      "181dccb82f624c1da1fff5dd0f2e3d5d",
      "f62ad8056c9942b292a55258869d127d",
      "af82cfec6fec4cbab07105c4e7be8447",
      "f91afb2197234ca9b77a88c2132d5c06"
     ]
    },
    "executionInfo": {
     "elapsed": 41093,
     "status": "ok",
     "timestamp": 1736922102903,
     "user": {
      "displayName": "川崎雄太",
      "userId": "13708483500900137948"
     },
     "user_tz": -540
    },
    "id": "ovolDJLv8eHc",
    "outputId": "638fae4e-1b41-404f-9b44-1e248278c85a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26299cf17869440981a8998dc7ac9216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title メインの処理ループ\n",
    "\n",
    "# フレームごとの処理を開始\n",
    "for _ in tqdm(range(video_src.frame_count)):\n",
    "    # 1. フレームの読み込み\n",
    "    drifting = video_src.read()\n",
    "    if drifting.img is None:  # 動画終了のチェック\n",
    "        break\n",
    "\n",
    "    # 2. 動き検出の実行\n",
    "    drifting = motion_detector.detect(drifting)\n",
    "\n",
    "    # 3. 検出結果の描画\n",
    "    drifting = detection_renderer.draw_result(drifting)\n",
    "\n",
    "    # 4. 結果の書き出し\n",
    "    drifting = video_sink.write(drifting)\n",
    "\n",
    "# 5. 終了処理\n",
    "video_sink.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wu74mxVlxbm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "181dccb82f624c1da1fff5dd0f2e3d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26299cf17869440981a8998dc7ac9216": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b6e28f789ca4604b29ce5f714cd891c",
       "IPY_MODEL_988f04379ee343c7a6b61af47bf82a90",
       "IPY_MODEL_3c33dadfbf73401e8035a2781a8b6c76"
      ],
      "layout": "IPY_MODEL_4dea107052924011a62a21a322c7a09d"
     }
    },
    "3c33dadfbf73401e8035a2781a8b6c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af82cfec6fec4cbab07105c4e7be8447",
      "placeholder": "​",
      "style": "IPY_MODEL_f91afb2197234ca9b77a88c2132d5c06",
      "value": " 256/256 [00:40&lt;00:00,  8.06it/s]"
     }
    },
    "4b6e28f789ca4604b29ce5f714cd891c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f77c6deb0204302b03b501c08802685",
      "placeholder": "​",
      "style": "IPY_MODEL_8ade06b9d59b4fb3a6756ee782304186",
      "value": "100%"
     }
    },
    "4dea107052924011a62a21a322c7a09d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ade06b9d59b4fb3a6756ee782304186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "988f04379ee343c7a6b61af47bf82a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_181dccb82f624c1da1fff5dd0f2e3d5d",
      "max": 256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f62ad8056c9942b292a55258869d127d",
      "value": 256
     }
    },
    "9f77c6deb0204302b03b501c08802685": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af82cfec6fec4cbab07105c4e7be8447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62ad8056c9942b292a55258869d127d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f91afb2197234ca9b77a88c2132d5c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
